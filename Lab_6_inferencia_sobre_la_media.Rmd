---
title: "Lab 5 - Inferencia sobre la media"
author: "Diego Martinez"
date: "`r Sys.Date()`"
output:
  pdf_document: default
  html_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Laboratorio 6: Inferencias sobre la media de una población

### Lecturas recomendadas

-   Capítulo 5.4 - Johnson, Richard A.; Wichern, Dean W. (2007). Applied Multivariate Statistical Analysis. Pearson Education. [https://www.webpages.uidaho.edu/book-link.pdf](https://www.webpages.uidaho.edu/~stevel/519/Applied%20Multivariate%20Statistical%20Analysis%20by%20Johnson%20and%20Wichern.pdf)

### Instalaciones previas para poder generar el documento en PDF del archivo

Para poder generar el documento en PDF será necesario instalar nuevas librerías (adicional a la de `knitr`). Para esto deberán copiar y pegar los siguientes comandos en la consola de R

```         
install.packages("knitr") 
install.packages("rmarkdown") 
install.packages("tinytex") 
tinytex::install_tinytex()
```

> En el caso de que ya tuvieran instaladas estas librerías les aparecerá una ventana indicando si desean reiniciar la sesión de R para actualizar o instalar dichas librerías. Tendrán que seleccionar "Si". Esto reiniciará la sesión de R y volverá a aparecer la misma ventana. En esta oportunidad deberán seleccionar la opción "No" para poder continuar con la instalación (o actualización) de estas librerías.

## El caso univariado

En el caso de una sola variable se puede plantear la siguiente hipótesis:

$$
H_0:\mu = \mu_o \\
H_1:\mu \neq \mu_o
$$

$H_o$ es la hipótesis nula y $H_1$ es la hipótesis alterna de dos colas. Si $x_{1,} x_{2\;,} x_3 ,\ldotp \ldotp \ldotp \ldotp x_n$ denotan una muestra aleatoria de una población normal, el test estadístico que nos sirva para evaluar $H_o$ es: $t=\frac{\left(\bar{X} -\mu_o \right)}{\frac{s}{\sqrt{n}}}$ donde, $\bar{X}$ y $s$ son la media y la desviación estandar de la muestra. Uno rechaza $H_o$ si el valor observado de $\left|t\right|$ excede un valor critico de la distribución t con n-1 grados de libertad (df). Rechazar $H_o$ si $\left|t\right|$ es grande es lo mismo que rechazar $H_o$ si $t^2$ es grande:

$$
t^2 =\frac{{n\left(\bar{X} -\mu_o \right)}^2 }{s^2 }=n\left(\bar{X} -\mu_o \right){\left(s^2 \right)}^{-1} \left(\bar{X} -\mu_o \right)
$$

$t^2$ es la distancia al cuadrado de la media de la muestra $\bar{X}$ a $\mu_{0}$. Las unidades están expresadas en unidades de $\frac{s}{\sqrt{n}}$. Una vez $\bar{X}$ y $s^2$ se observa (de la muestra) el test se convierte en: rechazo $H_o$ si:

$$
n\left(\bar{X} -\mu_o \right){\left(s^2 \right)}^{-1} \left(\bar{X} -\mu_o \right)>{t_{n-1} }^2 \left(\frac{\alpha }{2}\right)
$$

donde ${t_{n-1} }^2 \left(\frac{\alpha }{2}\right)$ denota el percentil superior $100\left(\frac{\alpha }{2}\right)$ de la distribución $t$ con $n-1$ df.

Si $H_o$ no se rechaza se concluye que $\mu_o$ es un valor posible de la media de la población. El intervalo de confianza contiene los valores de $\mu_o$ que pasan la prueba de hipótesis y se convierten en la región de posibles valores de la media.

$$ 
\left(\bar{X} -{t_{n-1} }^2 \left(\frac{\alpha }{2}\right)*\frac{s}{\sqrt{n}}\right)\le \mu_o \le \left(\bar{X} +{t_{n-1} }^2 \left(\frac{\alpha }{2}\right)*\frac{s}{\sqrt{n}}\right) 
$$

Este intervalo es un intervalo aleatorio en la medida que antes de colectar la media y la varianza existen muchos intervalos posibles. De esta manera la potabilidad que intervalo contenga $\mu$ es $\left(1-\frac{\alpha }{2}\right)$.

## El caso de más de una variable

si X tiene más de 1 columna, con variables correlacionadas las conceptos anteriores se pueden extender de forma natural. La distancia entre $\bar{X}$ y $\mu_{o}$ (ahora vectores con las dimensiones de las columnas de X) es:

$$ 
T^2 =n\left(\bar{X} -\mu_o \right){\left(S^2 \right)}^{-1} \left(\bar{X} -\mu_o \right) 
$$

donde S es la matriz varianza-covarianza. Si $T^2$ es muy grande $\bar{X}$ y $\mu$ estan muy lejos el uno del otro. $T^2$ esta distribuida $\frac{p\left(n-1\right)}{n-p}F_{p,n-p}$ es decir una distribución F con p,n-p df.

En la construcción de $T^2$ note que $\left(\bar{X} -\mu_o \right)$ tiene distribución normal, ${\left(S^2 \right)}^{-1}$ tiene distribución normal, de tal manera que la multiplicación de Normal x Chi x Normal resulta en una F. Al igual que el caso univariado, rechazo si T2 es muy grande:

$$ 
T^2 > \frac{p\left(n-1\right)}{n-p}F_{p,n-p} \left(\alpha \right) 
$$

Este indicador se conoce como la **prueba de Hotelling**. Para una sola variable se usa la prueba t y para p variables la prueba F.

## Regiones de confianza

Si $\theta$ es un vector de parámetros desconocidos sobre una población y $\ominus$ es el set de todos los posibles valores de $\theta$, una región de confianza es una región de valores posibles de $\theta$. Esta región esta determinada por los datos y la denotamos como $R(X)$ donde $X=X_1 ,X_2 ,\ldotp \ldotp \ldotp X_p$. Una región $R(X)$ se denota como una región de confianza al $100\left(\frac{\alpha }{2}\right)$, si:

$$ 
P\left\lbrack R\left(X\right)\;\mathrm{will}\;\mathrm{cover}\;\theta \right\rbrack =\;1-\alpha
$$

La región de confianza para una población de media $\mu$ y $p$ dimensiones está definida por:

$$
P\left\lbrack n\left(\bar{X} -\mu_o \right){\left(S^2 \right)}^{-1} \left(\bar{X} -\mu_o \right)\le \frac{p\left(n-1\right)}{n-p}F_{p,n-p} \left(\alpha \right)\right\rbrack =1-\alpha
$$

Cuando $p$ es igual a 2, se puede construir un elipsoide de confianza y sus longitudes relativas basado en los valores propios $\lambda_i$ y los vectores propios $e_i$ de $S$:

$$
\bar{X} \pm {\sqrt{\lambda }}_i \sqrt{\frac{p\left(n-1\right)}{n-p}F_{p,n-p} \left(\alpha \right)}e_i
$$

El elipsoide se puede construir con su respectiva ecuación paramétrica:

$$
X=\bar{X}+a*\cos{t}*e_1+b*\sin{t}*e_2
$$

Donde $e_1$ y $e_2$ corresponden a los valores propios de $S$, y $a$ y $b$ corresponden a los semiejes de la elipse, los cuales están definidos por los valores propios de $S$:

$$
a=\ \sqrt{\lambda_1}\sqrt{\frac{\left(n-1\right)p}{\left(n-p\right)}F_{p,n-p\left(\alpha\right)}} \\
b=\ \sqrt{\lambda_2}\sqrt{\frac{\left(n-1\right)p}{\left(n-p\right)}F_{p,n-p\left(\alpha\right)}}
$$

# Ejercicios

## Parte 1: Evaluación de la media de una variable

Starbucks, una cadena de cafés estadounidense fundada en Seattle, creó una base de datos con la información nutricional de todas las bebidas que ofrece en su menú como parte de una evaluación de nutrición en salud pública realizada por la OMS. Toda la información nutricional de las bebidas corresponde a una ración de 12 onzas. De las 6 variables nutricionales indicadas[^1], se seleccionaron únicamente dos:

[^1]: <https://www.kaggle.com/datasets/starbucks/starbucks-menu>

-   $X_1$: Calorías

-   $X_2$: Carbohidratos (g)

Cada uno de los datos para estas variables fueron registrados en la hoja de cálculo “Datos_Starbucks.xlsx”. Para estas dos variables:

1.  Evalúe la normalidad univariada (*Q-Q plot*) de las variables bajo un nivel de significancia del 1%.

```{r, warning=FALSE}
#primero hay que ver si vaiables son normales, si no, me toca transformar con gamma
library(readxl)
datos_starbucks <- read_excel("Datos_Starbucks.xlsx")


#Variable 1, calorias  ____________________________________________________________
filtro_x1 <- data.frame(datos_starbucks)[, c("Calories")]
x1 <- na.omit(filtro_x1)

x1_sorted <- sort(x1) # Ordenar los datos de menor a mayor
n1 <- length(x1) # calcular el numero de observaciones en la muestra
j1 <- seq(1, n1, 1) # crear un contador de 1 hasta el numero de datos
samplequartil_x1 <- (j1-1/2)/n1 # calcular el sample quartil 
# calcular el valor de la distribucion normal standard que corresponde a este nivel de acumulacion de probabilidad
q1 <- qnorm(samplequartil_x1)
r1 <- cor(cbind(q1, x1_sorted))

paste("Número de datos x1:", n1)
paste("Coeficiente de correlación x1:", r1[1, 2])

plot(q1, x1_sorted, col = "blue", pch = 19, main = "Scatter Plot X1", xlab = "normal standard value", ylab = "sample value")

#Variable 2, carbohidratos _______________________________________________
filtro_x2 <- data.frame(datos_starbucks)[, c("Carbs")]
x2 <- na.omit(filtro_x2)

x2_sorted <- sort(x2) # Ordenar los datos de menor a mayor
n2 <- length(x2) # calcular el numero de observaciones en la muestra
j2 <- seq(1, n2, 1) # crear un contador de 1 hasta el numero de datos
samplequartil_x2 <- (j2-1/2)/n2 # calcular el sample quartil 
# calcular el valor de la distribucion normal standard que corresponde a este nivel de acumulacion de probabilidad
q2 <- qnorm(samplequartil_x2)

plot(q2, x2_sorted, col = "blue", pch = 19, main = "Scatter Plot X2", xlab = "normal standard value", ylab = "sample value")
r2 <- cor(cbind(q2, x2_sorted))
paste("Número de datos x2:", n2)
paste("Coeficiente de correlación x2:", r2[1, 2])

```

-   ***Conclusiones:***

    ***Normalidad de X1:** Como el valor de r crítico para un n=75 y una significancia del 0.01 es de 0.9771, y el coeficiente de correlación (r1) entre q1 y x1_sorted es 0.9614, tenemos que r1 \< r crítico y, por ende, se rechaza H0; es decir, los datos de calorias de las bebidas de Starbucks no conforman una distribución normal.*

    **Normalidad de X2:** *Como el valor de r crítico para un n=75 y una significancia del 0.01 es de 0.9771, y el coeficiente de correlación (r2) entre q2 y x2_sorted es 0.9836, tenemos que r2 \> r crítico y, por ende, no se rechaza H0; es decir, los datos de carbohidratos de las bebidas de Starbucks conforman una distribución normal.*

2.  En caso de no cumplir con el supuesto de normalidad, aplique la transformación correspondiente para cada variable (puede aplicar la transformación de potencia u otra transformación).

```{r, warning=FALSE}
#Aplicamos transformación gamma solo a la variable x1
source("./funciones/power_transformation.R")
result <- power_transformation(as.matrix(datos_starbucks$Calories))
l <- result$l #diferentes valores de lambda
f <- result$F_m
lambda <- result$lambda
maxf <- result$fmax

# Plot l vs. f
plot(l, f, type = "l")

# Add lambda vs. maxf to the plot
points(lambda, maxf, col = "red", pch = 19)

paste("Lambda", lambda)

#aplico transformación
x1_transformado <- (x1 ^ lambda  - 1) / lambda

#reviso normalidad
x1_sorted <- sort(x1_transformado) # Ordenar los datos de menor a mayor
n1 <- length(x1_transformado) # calcular el numero de observaciones en la muestra
j1 <- seq(1, n1, 1) # crear un contador de 1 hasta el numero de datos
samplequartil_x1 <- (j1-1/2)/n1 # calcular el sample quartil 
# calcular el valor de la distribucion normal standard que corresponde a este nivel de acumulacion de probabilidad
q1 <- qnorm(samplequartil_x1)

paste("Número de datos x1:", n1)
paste("Coeficiente de correlación x1:", r1[1, 2])

plot(q1, x1_sorted, col = "blue", pch = 19, main = "Scatter Plot X1", xlab = "normal standard value", ylab = "sample value")
r1 <- cor(cbind(q1, x1_sorted))

```

3.  ¿Sería apropiado considerar un valor de 150 calorías en promedio para las bebidas de Starbucks?

<!-- -->

a.  Plantee su prueba de hipótesis.

$$
H_0 : \mu_1= 150 \\
H_1: \mu_1 \neq 150
$$

b.  Realice la prueba para la inferencia sobre la media de las calorías. Pueden utilizar el material de la clase de teoría (*"Lecturas y Material suplementario" \> "Material de la clase en R"*) o la función integrada en R (`t.test()`)

```{r, warning=FALSE}
valor_miu<- (150^lambda - 1) /lambda
test <- t.test(x1_transformado, , alternative = "two.sided", mu=valor_miu)
print(test)
```

c.  Indique los intervalos del 95% de confiabilidad para la inferencia de la media de las calorías. Pueden utilizar el material de la clase de teoría (*"Lecturas y Material suplementario" \> "Material de la clase en R"*) o la función integrada en R (`t.test()`)

```{r, warning=FALSE}
intervalo_confianza<-test$conf.int
print(intervalo_confianza)
print(valor_miu)
```

d.  Concluya respecto a su hipótesis.

-   *Conclusión: Con un intervalo de confianza del 95%, se observa que el valor de* $\mu_1$ *no se encuentra dentro del rango obtenido para la prueba de interferencia sobre la media de las calorías. El intervalo de confianza está comprendido entre 19.404 y 24.094, mientras que el valor de la media transformada es de 26.790, lo que indica que el estadístico de prueba no se encuentra dentro de este rango. Adicionalmente, se obtuvo un p-value de 5.452e-05, que es significativamente menor a una significancia de 0.05. Por lo tanto, se rechaza la hipótesis nula* ($H_0$) *que sugiere que las bebidas de Starbucks tienen un valor promedio de 150 calorías.*

4.  ¿Sería apropiado considerar valores de 20 gramos de carbohidratos en promedio para las bebidas de Starbucks?

<!-- -->

a.  Plantee su prueba de hipótesis.

$$
H_0:  \mu_2 = 20\\
H_1: \mu_2 \neq 20
$$

b.  Realice la prueba para la inferencia sobre la media de los carbohidratos Pueden utilizar el material de la clase de teoría (*"Lecturas y Material suplementario" \> "Material de la clase en R"*) o la función integrada en R (`t.test()`)

```{r, warning=FALSE}
test_x2 <- t.test(x2, alternative = "two.sided", mu = 20)

print(test_x2)
```

c.  Indique los intervalos del 95% de confiabilidad para la inferencia de la media de los carbohidratos. Pueden utilizar el material de la clase de teoría (*"Lecturas y Material suplementario" \> "Material de la clase en R"*) o la función integrada en R (`t.test()`)

```{r, warning=FALSE}
intervalo_x2 <- test_x2$conf.int
print(intervalo_x2)

```

d.  Concluya respecto a su hipótesis.

-   *Conclusión:* Con una confianza del 95%, se rechaza H0 dado que un valor de media $\mu_2$ de $20$ no esta en el intervalo de confianza $[24.68918, 25.47082]$ y, además, el p-value obtenido en el test da mucho menor a 5%, que es la significancia. Entonces, no sería apropiado considerar valores de 20 gramos de carbohidratos en promedio para las bebidas de Starbucks.

## Parte 2: Evaluación de la media de 2 variables

A partir de la misma base de datos con la información nutricional de las bebidas del menú de Starbucks, se desean realizar inferencias sobre la media de ambas variables

1.  Evalúe la normalidad bivariada (*Gamma plot*) de las variables bajo un nivel de significancia del 1%.

```{r, warning=FALSE}

Datos_Starbucks<-datos_starbucks

mean_cov_corr_matrices <- function(X) {
#   %This function computes the Mean(M), the Variance - Covariance Matrix (VC)
#   %and the Correlation Matrix (R).
#   % The mean is computed by defining an n by 1 vector (1) that has equal angles
#   % with all the axes (observations)and the vector 1/(sqrt(n)) has unit
#   % lenght in the equal angle direction. Consider the vector yi = [x1i x2i
#   % ...xni](all values for one variable - column in X). The projection of yi
#   % on the vector 1 (by definition the proyection of x on y is (x'y/(y'y))*y)
#   % which es equal to (xi1 + x2i + ...xni)/n * 1 -> the mean vector. The mean
#   % is the proyection of the obeservation vector on the unit lenght vector of
#   % equal angles and the deviation from mena is the perperdicular distance of
#   % this two vectors. 
#   %The Variance - Covariance Matrix contains the variance 
#   %Skk = (1/(n-1)*sum((xji-mean(yi)^2)
#   
#   %in the diagonal and Sik = (1/(n-1)*sum((xji-mean(yi)*(xjk-mean(yk))
#   %outside the diagonal. The matrix is symetric.
#   %The sample correlation coefficient (linear association between two
#                                        %variables). Rik = Sik/(sqrt(Sii)sqrt(Skk)). 
#   % Is the standarization of the sample covariance provided by the square root of 
#   #sample variance of each variable.
#   %
#   %INPUT X a n by p matrix. n observation on p variables
#   %
#   %OUTPUT M Mean p by 1 vector
#   %       VC Variance - Covariance Matrix. p by p matrix 
#   %       R Correlation matrix. p by p matrix 
# 
# %--------------------------------------------------------------------------
  
  
  # Calcula la media M
  n <- nrow(X)
  p <- ncol(X)
  O <- matrix(1, n, 1)
  M <- (1/n) * t(X) %*% O
  
  # Matriz de desviaciones D
  Mr <- (1/n) * (O %*% t(O)) %*% as.matrix(X)
  D <- as.matrix(X) - Mr
  
  # Matriz de varianza-covarianza VC
  VC <- (1/(n-1)) * t(D) %*% D
  
  # Matriz de correlación R
  SD <- sqrt(diag(VC))
  SDinv <- solve(diag(SD))
  R <- SDinv %*% VC %*% SDinv
  
  return(list(M = M, VC = VC, R = R))
}

bivariate_normality <- function(X) {
  # detecta normalidad para una y 2+ variables
  # chequear si X tiene una sola columna o varias
  if ("data.frame" %in% class(X)){
    X <- as.matrix(X)
  }
  
  nc <- ncol(X)
  nr <- nrow(X)
  if (nc == 1) {
    # QQ plot
    xsorted <- sort(X)
    j <- 1:nr
    samplequartil <- (j - 0.5) / nr
    q <- qnorm(samplequartil)
    T <- data.frame(xsorted = xsorted, samplequartil = samplequartil, q = q)
    nvec <- NULL
  } else {
    result <- mean_cov_corr_matrices(X)
    M <- result$M
    print(dim(M))
    VC <- result$VC
    print(VC)
    SI <- solve(VC)
    print(dim(SI))
    GD <- numeric(nr)
    for (i in 1:nr) {
      GD[i] <- t((X[i,]) - M) %*% SI %*% ((X[i,]) - M)
    }
    vc <- qchisq(0.5, nc)
    nvec <- (nr - sum(GD > vc)) / nr
    GDsorted <- sort(GD)
    ChiSquare <- numeric(nr)
    for (i in 1:nr) {
      ChiSquare[i] <- qchisq((i - 0.5) / nr, nc)
    }
    comparison <- GDsorted > vc
    Observations <- 1:nr
    T <- data.frame(Observations = Observations, GDsorted = GDsorted, ChiSquare = ChiSquare, comparison = comparison)
  }
  return(list(T = T, nvec = nvec))
}

n <- nrow(Datos_Starbucks)
paste("longitud", n)

result <- bivariate_normality(Datos_Starbucks)

T <- result$T
nvec <- result$nvec
paste("proporcion", nvec)
# Plot Chi-square vs. sorted generalized distance
plot(T$ChiSquare, T$GDsorted, type = "p", col = "black", pch = 19, cex =
1.5, xlab = "Chi-Square", ylab = "Generalized Distance (sorted)", main =
"Chi-Square vs. Generalized Distance")


r <- cor(T$ChiSquare, T$GDsorted) # calcula el coefficiente de correlacion entre Chi y GD)
print(r)






```

Conclusiones: Como el valor de r crítico para un n=75 y una significancia del 0.01 es de 0.9771, y el coeficiente de correlación (r) entre ChiSquare y GDsorted es 0.9580723, tenemos que r \< r crítico y, por ende, se rechaza la H0; es decir, los datos no son normales

$$ x^{\lambda} = \begin{cases} (x^{\lambda}-1)/\lambda & \lambda \neq 0 \\ 
\text{ln} \ \lambda & \lambda = 0 \end{cases} \\ $$

2.  En caso de no cumplir con el supuesto de normalidad, aplique la transformación correspondiente para cada variable (puede aplicar la transformación de potencia u otra transformación).

```{r, warning=FALSE}

x_1 <- Datos_Starbucks$Calories
x_2 <- Datos_Starbucks$Carbs

lambda_transformacion <- function(lambda, x) {
  if (lambda == 0) {
    transformacion <- log(x)  # log transformation for lambda = 0
  } else {
    transformacion <- (x^lambda - 1) / lambda  # apply the transformation
  }
  return(transformacion)
}

power_transformation <- function(X) {
 # ensayar varios valores de lambda 
 l <- seq(-2, 2, by = 0.01)
 nl <- length(l)
 nc <- ncol(X)
 nr <- nrow(X)
 F_m <- matrix(0, nrow = nl, ncol = nc)
 lambda <- numeric(nc)
 fmax <- numeric(nc)
 for (p in 1:nc) { #para cada columna de X
 for (i in 1:nl) { #para cada valor de lambda
 x <- X[, p] #seleccione la variable
 if (l[i] != 0) {
 xl <- ((x^l[i]) - 1) / l[i] #calcule la potencia (x^l-1)/l
 } else {
 xl <- log(x) #calcule cuando l es 0 
 }
 xlm <- mean(xl) #saque la media 
 sl <- (xl - xlm)^2 #saque la varianza
 F_m[i, p] <- -nr/2 * log(1/nr * sum(sl)) + (l[i] - 1) * sum(log(x)) 
#calcula la funcion de lambda
 }
 ix <- which.max(F_m[, p])
 lambda[p] <- l[ix]
 fmax[p] <- max(F_m[, p])
 }
 return(list(l = l, F_m = F_m, lambda = lambda, fmax = fmax))
}

result <- power_transformation(as.matrix(x_1))
l <- result$l
f <- result$F_m
lambda1 <- result$lambda
lambda1
maxf <- result$fmax

# Plot l vs. f
plot(l, f, type = "l")

# Add lambda vs. maxf to the plot
points(lambda1, maxf, col = "red", pch = 19)


result2 <- power_transformation(as.matrix(x_2))
l2 <- result2$l
f2 <- result2$F_m
lambda2 <- result2$lambda
lambda2

maxf <- result2$fmax
# Plot l vs. f
plot(l2, f2, type = "l")
# Add lambda vs. maxf to the plot
points(lambda2, maxf, col = "red", pch = 19)

transformacion1 <- lambda_transformacion(lambda1,x_1)
transformacion1
transformacion2 <- lambda_transformacion(lambda2,x_2)
transformacion2


qqnorm(transformacion1, main = "QQ Plot: Calorias transformados")
qqline(transformacion1, col = "cyan")

qqnorm(transformacion2, main = "QQ Plot: Carbohidratos transformados")
qqline(transformacion2, col = "deeppink")

Transformados_Datos_starbucks <- cbind(transformacion1, transformacion2) 
n3 <- nrow(Transformados_Datos_starbucks)
paste("longitud", n3)

result3 <- bivariate_normality(Transformados_Datos_starbucks)

T <- result3$T
nvec <- result$nvec
paste("proporcion", nvec)
# Plot Chi-square vs. sorted generalized distance
plot(T$ChiSquare, T$GDsorted, type = "p", col = "gold", pch = 10, cex =
1, xlab = "Chi-Square", ylab = "Generalized Distance (sorted)", main =
"Chi-Square vs. Generalized Distance")


r <- cor(T$ChiSquare, T$GDsorted) # calcula el coeficiente de correlacion entre Chi y GD)
print(r)



```

Conclusiones: Como el valor del r crítico, después de la transformación, para un n=75 y una significancia del 0.01 es de 0.9771, y el coeficiente de correlación (r) entre ChiSquare y GDsorted es 0.9729087, tenemos que r \< r crítico y, por ende, se rechaza la H0; es decir, los datos aun siguen sin ser normales, no obstante, los datos transformados están muy cerca de ser datos con una distribución norma, por ese motivo, se podría considerar que las razones de que aun siguen sin ser datos con un comportamiento normal, es debido a los outliers o datos mas extremos que se posee en la tabla. Igualmente,Esto sugiere que, aunque los datos transformados no son completamente normales, la transformación ha mejorado notablemente su distribución

3.  ¿Sería apropiado considerar una media de $(120,25)$ para las calorías y los gramos de carbohidratos de las bebidas de Starbucks?

<!-- -->

a.  Plantee su prueba de hipótesis.

$$
H_0: \mu = (120\,,25)\\
H_1: \mu ≠ (120\,,25)\\
$$ datos transformados $$
H_0: \mu = (62.39401\,,23.48569)\\
H_1: \mu ≠ (62.39401\,,23.48569)\\
$$

b.  Realice la prueba para la inferencia sobre la media. Pueden utilizar el material de la clase de teoría (*"Lecturas y Material suplementario" \> "Material de la clase en R"*) o la función `HottelingsT2Test()` de la librería [Desctools](https://search.r-project.org/CRAN/refmans/DescTools/html/HotellingsT.html).

```{r, warning=FALSE}

#Metodo 1
#se transforma los puntos de (120,25)

transformacion3 <- lambda_transformacion(lambda1,120)
transformacion4 <- lambda_transformacion(lambda2,25)

transformacion3
transformacion4



#Se tomo una significancia de 1%
result4 <- mean_cov_corr_matrices(Transformados_Datos_starbucks)
M <- result4$M
VC <- result4$VC

n <- nrow(Transformados_Datos_starbucks)
nc <- ncol(Transformados_Datos_starbucks)

Uo <- c(transformacion3,transformacion4)
T2 <- n * t(M - Uo) %*% solve(VC) %*% (M - Uo)
T2

Fcritico <- qf(1-0.01, nc, n - nc)
Fcritico

Tcritico = Fcritico*nc*(n-1)/(n-nc)
Tcritico
```

Como $T^2$ es MENOR que $T_{critico}$ no rechazamos la $H_o$. Ese vector de medias parece sugerir ser un vector adecuado para describir de manera conjunta la medias de las variables

```{r, warning=FALSE}

#Metodo 2
install.packages("DescTools")
library(DescTools)

Uo <- c(transformacion3,transformacion4)

X <- as.matrix(Transformados_Datos_starbucks)

hotelling_test <- HotellingsT2Test(X, mu = Uo)
print(hotelling_test)
print(hotelling_test$p.value)

# Conclusion:
if (hotelling_test$p.value < 0.01) {
  print("Rechazamos la hipotesis nula, sugiriendo que el vector de la media (23.48569, 62.39401) no es el apropiado.")
} else {
  print("No Rechazamos la hipotesis nula, sugiriendo que el vector de la media (23.48569, 62.39401) podria ser el apropiado.")
}


```


c.  Indique las elipses del 95% de confiabilidad para la inferencia de la media de las calorías. Pueden utilizar el material de la clase de teoría (*"Lecturas y Material suplementario" \> "Material de la clase en R"*). También existe una función (`MVcis()`) de la librería [mvdalab](https://rdrr.io/cran/mvdalab/man/MVcis.html), aunque su estética no es tan buena.

```{r, warning=FALSE}
install.packages("mvdalab")
library(mvdalab)
#Metodo 1
X <- as.matrix(Transformados_Datos_starbucks)

result <- mean_cov_corr_matrices(X)
result$M
M <- result$M  
VC <- result$VC  

n <- nrow(X)
p <- ncol(X)

alpha <- 0.05  # 95% 

eig_result <- eigen(VC)
eVect <- eig_result$vectors  
eVal <- eig_result$values    

eVal[c(1, 2)] <- eVal[c(2, 1)]
eVal <- diag(eVal)
eVect[, c(1, 2)] <- eVect[, c(2, 1)]

a <- sqrt(eVal[1, 1]) * sqrt(qf(1 - alpha, p, n - p) * p * (n - 1) / (n * (n - p)))  # Axis 1
b <- sqrt(eVal[2, 2]) * sqrt(qf(1 - alpha, p, n - p) * p * (n - 1) / (n * (n - p)))  # Axis 2

t <- seq(0, 2 * pi, by = 0.01)
nt <- length(t)
ellipse_coords <- matrix(0, nrow = nt, ncol = 2)
for (k in 1:nt) {
  ellipse_coords[k, ] <- (M + a * cos(t[k]) * eVect[, 1] + b * sin(t[k]) * eVect[, 2])
}

x1l <- M[1] - sqrt(qf(1 - alpha, p, n - p) * p * (n - 1) / (n * (n - p))) * sqrt(VC[1, 1])
x1r <- M[1] + sqrt(qf(1 - alpha, p, n - p) * p * (n - 1) / (n * (n - p))) * sqrt(VC[1, 1])
x2l <- M[2] - sqrt(qf(1 - alpha, p, n - p) * p * (n - 1) / (n * (n - p))) * sqrt(VC[2, 2])
x2r <- M[2] + sqrt(qf(1 - alpha, p, n - p) * p * (n - 1) / (n * (n - p))) * sqrt(VC[2, 2])

plot(X[, 1], X[, 2], col = rgb(0.1, 0.3, 0.7, alpha = 0.4), pch = 19, cex = 0.8, 
     main = "Intervalo de confianza para el 95%", 
     xlim = c(min(X[, 1]), max(X[, 1])), ylim = c(min(X[, 2]), max(X[, 2])),
     xlab = "Calorias", ylab = "Carbs")

lines(ellipse_coords[, 1], ellipse_coords[, 2], col = "red", lwd = 2)

points(M[1], M[2], col = "red", pch = 19, cex = 1.5)

shadow_x1 <- seq(x1l, x1r, length.out = 100)
shadow_y1 <- rep(min(X[, 2]), 100)
lines(shadow_x1, shadow_y1, col = "green", lwd = 3)

shadow_x2 <- rep(min(X[, 1]), 100)
shadow_y2 <- seq(x2l, x2r, length.out = 100)
lines(shadow_x2, shadow_y2, col = "green", lwd = 3)

points(X[, 1], X[, 2], col = rgb(0.1, 0.3, 0.7, alpha = 0.5), pch = 19, cex = 0.4)
points(transformacion3,transformacion4,col ="cyan", alpha = 1.5, pch = 19, label= "Media de $(120,25)$ para las calorías")

legend("topright", legend = c("Puntos de calorias y carbohidratos", "Elipse del 95%", "Media de (120,25)"), 
       col = c(rgb(0.1, 0.3, 0.7, alpha = 0.5), "red", "cyan"), 
       pch = c(19, NA, 19), lty = c(NA, 1, NA), lwd = c(NA, 2, NA),
       pt.cex = c(0.8, NA, 1.5))

ad <- sqrt(eVal[1, 1]) * sqrt(qf(1 - alpha, p, n - p) * p * (n - 1) / (n * (n - p))) * sqrt(VC[1, 1] - 2 * VC[2, 1] + VC[2, 2])
bd <- sqrt(eVal[2, 2]) * sqrt(qf(1 - alpha, p, n - p) * p * (n - 1) / (n * (n - p))) * sqrt(VC[1, 1] - 2 * VC[2, 1] + VC[2, 2])

t <- seq(0, 2 * pi, by = 0.01)
nt <- length(t)
xd <- matrix(0, nrow = nt, ncol = 2)

mean_diff <- M[1] - M[2]

for (k in 1:nt) {
  xd[k, ] <- (mean_diff + ad * cos(t[k]) * eVect[, 1] + bd * sin(t[k]) * eVect[, 2])
}

plot(xd[, 1], xd[, 2], type = "p", col = rgb(0.1, 0.3, 0.7, alpha = 0.5), pch = 19, cex = 0.4,
     main = "Intervalo de confianza de la diferencia entre calorias y carbohidratos",
     xlab = "Diferencia en Calorias", ylab = "Diferencia en Carbs")

points(mean_diff, 0, col = "red", pch = 19, cex = 1.5)

grid()



```
```{r, warning=FALSE}

#Metodo 2
library(mvdalab)
#Convertirlo en dataframe
Transformados_Datos_starbucks_df <- as.data.frame(Transformados_Datos_starbucks)

result_ellipse <- MVcis(Transformados_Datos_starbucks_df,level=0.95)

plot(result_ellipse["Calories"],result_ellipse["Carbs"], main = "intervalo de confianza del 95%", 
     xlab = "Calorias", ylab = "Carbs", col = "red",xlim = c(min(X[, 1]), max(X[, 1])), ylim = c(min(X[, 2]), max(X[, 2])))

lines(result_ellipse[1], result_ellipse[2], col = "red", lwd = 2)


points(X[, 1], X[, 2], col = rgb(0.1, 0.3, 0.7, alpha = 0.5), pch = 19, cex = 0.4)

mean_diff <- mean(X[, 1]) - mean(X[, 2])

points(mean(X[, 1]), mean(X[, 2]), col = "red", pch = 19, cex = 1.5)
text(mean(X[, 1]), mean(X[, 2]), pos = 4, col = "red")


legend("topright", legend = c("Puntos de datos de Starbucks", "Intervalo del 95%", "Media de (62.39401,23.48569)"),
       col = c(rgb(0.1, 0.3, 0.7, alpha = 0.5), "red", "red"),
       pch = c(19, NA, 19), lty = c(NA, 1, NA), lwd = c(NA, 2, NA), pt.cex = c(0.8, NA, 1.5))



```

d.  Concluya respecto a su hipótesis.

-   *Conclusión: Al observar tanto la elipse del método 1 y método 2, al igual que,la prueba para la inferencia sobre la media del punto b), se puede afirma con un 95% de confianza que la media (62.39401,23.48569) es una media apropiada para las calorías y carbohidratos en los datos de Starbucks. Dado que se encuentra el punto (62.39401,23.48569) dentro de la elipse de confianza, no se rechaza la hipótesis nula de *$H_0: \mu = (62.39401\,,23.48569)$.
